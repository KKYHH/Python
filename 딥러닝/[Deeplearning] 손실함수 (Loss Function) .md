# [Deeplearning] 손실함수 (Loss Function)

# 손실함수 (Loss Function)

## 손실함수란?

손실함수는 딥러닝 모델의 학습 과정에서 모델의 예측값과 실제값의 차이를 계산하여 모델의 성능을 평가하는 함수입니다. **즉, 모델이 예측한 값과 실제 값 사이의 오차를 측정하는 지표로 사용됩니다.**

## 손실함수의 종류

손실함수는 딥러닝 모델의 종류와 문제에 따라 다양한 종류가 존재합니다. 

일반적으로 회귀 문제에는 **평균 제곱 오차(MSE)** 함수가 사용되고, 

분류 문제에는 **교차 엔트로피(Cross-Entropy)** 함수가 사용됩니다.

## 평균 제곱 오차 (MSE)

평균 제곱 오차는 회귀 문제에서 가장 기본적으로 사용되는 손실함수입니다. 

모델이 예측한 값과 실제 값의 차이를 제곱하여 평균을 구합니다. 

**이 값이 작을수록 모델의 성능이 좋다고 판단됩니다.**

## 교차 엔트로피 (Cross-Entropy)

교차 엔트로피는 분류 문제에서 사용되는 손실함수입니다. 

모델이 예측한 값과 실제 값의 차이를 계산하여 오차를 측정합니다. 

**이 값이 작을수록 모델의 성능이 좋다고 판단됩니다.**

## 결론

손실함수는 딥러닝 모델의 성능을 평가하는 지표로 사용되며, 문제에 따라 적절한 손실함수를 선택하는 것이 중요합니다. 

**평균 제곱 오차와 교차 엔트로피는 가장 기본적이고 널리 사용되는 손실함수입니다.**

## 이외의 손실함수

평균 제곱 오차와 교차 엔트로피 외에도 다양한 손실함수가 존재합니다. 예를 들어, 이진 분류 문제에서는 이진 교차 엔트로피(binary cross-entropy) 함수가 사용되며, 다중 분류 문제에서는 다중 교차 엔트로피(multi-class cross-entropy) 함수가 사용됩니다. 

또한, 이미지 분할 문제에서는 픽셀별 교차 엔트로피 함수가 사용됩니다.

## 손실함수 최적화

딥러닝 모델의 학습 과정에서는 손실함수를 최소화하는 파라미터를 찾는 과정이 필요합니다. 

이를 위해 **경사 하강법(Gradient Descent) 알고리즘**이 사용됩니다. 

경사 하강법은 손실함수의 기울기를 구하고, 이 기울기를 이용하여 파라미터를 업데이트하는 방법입니다.

## 참고 자료

- [딥러닝을 위한 손실 함수 이야기](https://blog.naver.com/navehag/221988130755)
- [손실 함수 - 위키백과](https://ko.wikipedia.org/wiki/%EC%86%90%EC%8B%A4_%ED%95%A8%EC%88%98)