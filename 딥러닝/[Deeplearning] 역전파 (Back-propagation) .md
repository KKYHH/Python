# [Deeplearning] 역전파 (Back-propagation)

# 역전파 (Back-propagation)

딥러닝에서 **역전파는 인공신경망 학습에 필수적인 알고리즘 중 하나입니다.** 

역전파 알고리즘은 인공신경망의 **가중치(weight)를 학습**시키기 위한 방법으로, 

출력값과 지도 데이터 사이의 오차를 이용하여 가중치를 업데이트 합니다.

역전파 알고리즘은 다음과 같은 과정으로 이루어집니다.

1. 순전파(Forward propagation): 입력값을 넣어서 출력값을 계산하는 과정입니다. 이때 가중치와 편향을 고려하여 계산합니다.
2. 오차 계산(Error calculation): 출력값과 지도 데이터 사이의 오차를 계산합니다.
3. 역전파(Back propagation): 오차를 이용하여 각 가중치의 기울기(gradient)를 계산합니다.
4. 가중치 업데이트(Weight update): 계산된 기울기를 이용하여 가중치를 업데이트 합니다.
5. 1~4 과정을 반복하여 오차를 최소화하고 가중치를 학습시킵니다.

역전파 알고리즘은 딥러닝에서 가장 많이 사용되는 학습 방법 중 하나이며, 다양한 변형 버전이 존재합니다. 

따라서 역전파 알고리즘을 이해하고 응용하는 것은 딥러닝 학습에 있어서 매우 중요합니다.

역전파 알고리즘의 한계점 중 하나는 **그레디언트 소멸 문제(Gradient vanishing problem)** 입니다. 

이는 심층 신경망에서 역전파 알고리즘이 깊은 층(layer)으로 갈수록 그레디언트(gradient) 값이 소실되어 학습이 어려워지는 현상입니다. 

이를 해결하기 위해 다양한 기법들이 제안되고 있으며, 예를 들어 **ReLU**와 같은 활성화 함수를 사용하거나, Skip Connection과 같은 아키텍처를 적용함으로써 그레디언트 소멸 문제를 완화할 수 있습니다.